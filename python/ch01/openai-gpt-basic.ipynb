{"cells":[{"cell_type":"markdown","metadata":{"id":"vJct1b7Ip5lP"},"source":["# OpenAI GPT models with Python\n","\n","This notebook provides a simple example of how to use the OpenAI GPT models with Python."]},{"cell_type":"markdown","source":["## 1. Setup\n","\n","To use the OpenAI API, you need to have an API key:\n","\n","1. Create or log into your [OpenAI account](https://platform.openai.com/)\n","2. Go to [API Keys](https://platform.openai.com/api-keys)\n","3. Click \"Create new secret key\", name it, copy it immediately\n","4. Add billing/payment details so the key becomes active (the API is pay-per-use)\n","\n","Once you have the API key, you need to export its value as and environment variable called `OPENAI_API_KEY`. If this env is not defined, you will be asked for your API key (it will not be stored in the notebook)."],"metadata":{"id":"QaTx1r2xtcrm"}},{"cell_type":"code","source":["import os\n","from getpass import getpass\n","from openai import OpenAI\n","\n","# Ask for the API key interactively if not defined as env variable\n","if \"OPENAI_API_KEY\" not in os.environ:\n","    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n","\n","client = OpenAI()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y6KqRHr0t7gx","executionInfo":{"status":"ok","timestamp":1764692336278,"user_tz":-60,"elapsed":10562,"user":{"displayName":"Boni García","userId":"07441265877940459995"}},"outputId":"ce1da798-1b4e-4f68-d89f-41324a24d693"},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your OpenAI API key: ··········\n"]}]},{"cell_type":"markdown","source":["## 2. Function to ask the model\n","\n","This section defines a helper function to send a user prompt to the model using the previously defined OpenAI client."],"metadata":{"id":"bTQ1T0dPt8NY"}},{"cell_type":"code","source":["def ask_model(prompt: str, model: str = \"gpt-4.1-mini\") -> str:\n","    \"\"\"Send a text prompt an OpenAI model and return the text response\"\"\"\n","    response = client.responses.create(\n","        model=model,\n","        input=prompt,\n","    )\n","    # The output format may evolve over time; this is correct at the time of writing.\n","    return response.output[0].content[0].text"],"metadata":{"id":"f2JARYnDuAVw","executionInfo":{"status":"ok","timestamp":1764692338475,"user_tz":-60,"elapsed":15,"user":{"displayName":"Boni García","userId":"07441265877940459995"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## 3. Send user prompt\n","\n","This section sends and user prompt to the model using the function previously defined."],"metadata":{"id":"FKmAvGgluKJZ"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFdaS5MBp5lU","executionInfo":{"status":"ok","timestamp":1764692343507,"user_tz":-60,"elapsed":3636,"user":{"displayName":"Boni García","userId":"07441265877940459995"}},"outputId":"554d0267-37ce-4388-b135-f7a9bef592cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["User: How many tokens is your context window?\n","AI: My context window is 32,768 tokens. This means I can process and keep track of up to roughly 32,768 tokens of text in a single interaction.\n"]}],"source":["user_prompt = \"How many tokens is your context window?\"\n","response = ask_model(user_prompt)\n","print(\"User: \" + user_prompt)\n","print(\"AI: \" + response)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}