# Observability and tracing with Langfuse

This example demonstrates the concept of **observability** in context-aware AI systems by using `Langfuse` to trace the execution of a multi-step AI agent. It shows how to capture detailed information about an agent's reasoning process, tool usage, and LLM calls, which is essential for debugging, evaluation, and monitoring.

## Requirements

This project requires [Python](https://www.python.org/) 3.6+ and the libraries listed in `requirements.txt`. You will also need an account with [Langfuse](https://langfuse.com/) (cloud or self-hosted) and an OpenAI API key.

## Steps for running this example

1.  Install dependencies:
```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\\Scripts\\activate
pip install -r requirements.txt
```

2.  Configure your credentials:
* Create a `.env` file in this directory.
* Add your credentials from your Langfuse project settings and your OpenAI API key:
```
LANGFUSE_PUBLIC_KEY="pk-lf-..."
LANGFUSE_SECRET_KEY="sk-lf-..."
LANGFUSE_HOST="https://cloud.langfuse.com"
OPENAI_API_KEY="sk-..."
```

3.  Run the script:
```bash
python observability_tracing.py
```

## Output

The script will run a simple AI agent that uses a search tool to answer a question. As it runs, you will see the agent's internal monologue printed to the console (because `verbose=True`).

At the end, the script will print:
1.  A URL to the full, detailed trace in your Langfuse project.
2.  The final answer generated by the agent.

You can visit the Langfuse URL to see a complete, step-by-step visualization of the agent's execution, including thoughts, tool calls, and LLM inputs/outputs.